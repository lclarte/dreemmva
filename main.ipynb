{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondab01880b39f9c4020a8d680b488ee4bca",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load nn model from braindecode\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from braindecode.models.deep4 import Deep4Net\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "import core.data as data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started loading file data/x_train.h5\nFinished loading the file.\nStarted loading file data/y_train.csv\nFinished loading the file.\n"
    }
   ],
   "source": [
    "# load data \n",
    "x_loaded, y_loaded = data.load_x('data/x_train.h5'), data.load_y('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights(y):\n",
    "    class_sample_count = np.array(\\\n",
    "                [len(np.where(y == t)[0]) for t in range(2)])\n",
    "    return float(len(y)) / class_sample_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "shape :  (24974, 7, 500) (12866, 7, 500) (24974,) (12866,)\nweights : [1.28931337 4.45645967]\n"
    }
   ],
   "source": [
    "# convert y to categorical with np.eye(d)[y_loaded]\n",
    "# and flatten the 40 independent samples\n",
    "x, y = data.flatten_x(x_loaded), data.flatten_y(y_loaded, repeat=40)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.66)\n",
    "x_train, x_test = x_train.squeeze(), x_test.squeeze()\n",
    "\n",
    "# Only one value : 0 or 1  \n",
    "y_train, y_test = np.argmax(y_train, axis=1), np.argmax(y_test, axis=1)\n",
    "\n",
    "# get class weights\n",
    "weights = class_weights(y_train)\n",
    "\n",
    "print('shape : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print('weights :', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = x_train.shape[1]\n",
    "input_time_length=x_train.shape[2]\n",
    "final_conv_length='auto'\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = Deep4Net(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=input_time_length,\n",
    "                        final_conv_length=final_conv_length)\n",
    "\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "criterion = lambda prediction, targets : F.nll_loss(prediction, targets, weight=torch.from_numpy(weights).float())\n",
    "model.compile(loss=criterion, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-08 19:30:05,347 INFO : Run until first stop...\n2020-02-08 19:30:34,516 INFO : Epoch 0\n2020-02-08 19:30:34,517 INFO : train_loss                19.16027\n2020-02-08 19:30:34,517 INFO : valid_loss                21.30436\n2020-02-08 19:30:34,518 INFO : train_misclass            0.25010\n2020-02-08 19:30:34,518 INFO : valid_misclass            0.24576\n2020-02-08 19:30:34,519 INFO : runtime                   0.00000\n2020-02-08 19:30:34,519 INFO : \n2020-02-08 19:32:23,659 INFO : Time only for training updates: 109.14s\n2020-02-08 19:32:55,943 INFO : Epoch 1\n2020-02-08 19:32:55,944 INFO : train_loss                0.69845\n2020-02-08 19:32:55,945 INFO : valid_loss                0.69673\n2020-02-08 19:32:55,946 INFO : train_misclass            0.23372\n2020-02-08 19:32:55,948 INFO : valid_misclass            0.22470\n2020-02-08 19:32:55,949 INFO : runtime                   138.31089\n2020-02-08 19:32:55,951 INFO : \n2020-02-08 19:35:34,704 INFO : Time only for training updates: 158.75s\n2020-02-08 19:36:37,838 INFO : Epoch 2\n2020-02-08 19:36:37,845 INFO : train_loss                0.69692\n2020-02-08 19:36:37,846 INFO : valid_loss                0.69555\n2020-02-08 19:36:37,846 INFO : train_misclass            0.23797\n2020-02-08 19:36:37,847 INFO : valid_misclass            0.22952\n2020-02-08 19:36:37,847 INFO : runtime                   191.04401\n2020-02-08 19:36:37,848 INFO : \n2020-02-08 19:39:20,477 INFO : Time only for training updates: 162.63s\n2020-02-08 19:40:19,935 INFO : Epoch 3\n2020-02-08 19:40:19,936 INFO : train_loss                0.70344\n2020-02-08 19:40:19,937 INFO : valid_loss                0.69976\n2020-02-08 19:40:19,938 INFO : train_misclass            0.23428\n2020-02-08 19:40:19,938 INFO : valid_misclass            0.22478\n2020-02-08 19:40:19,941 INFO : runtime                   225.77406\n2020-02-08 19:40:19,941 INFO : \n2020-02-08 19:42:27,642 INFO : Time only for training updates: 127.70s\n2020-02-08 19:42:57,193 INFO : Epoch 4\n2020-02-08 19:42:57,194 INFO : train_loss                0.70899\n2020-02-08 19:42:57,194 INFO : valid_loss                0.70355\n2020-02-08 19:42:57,199 INFO : train_misclass            0.23024\n2020-02-08 19:42:57,199 INFO : valid_misclass            0.22097\n2020-02-08 19:42:57,202 INFO : runtime                   187.16495\n2020-02-08 19:42:57,202 INFO : \n2020-02-08 19:44:59,306 INFO : Time only for training updates: 122.10s\n2020-02-08 19:45:38,828 INFO : Epoch 5\n2020-02-08 19:45:38,829 INFO : train_loss                0.70552\n2020-02-08 19:45:38,830 INFO : valid_loss                0.70128\n2020-02-08 19:45:38,830 INFO : train_misclass            0.23601\n2020-02-08 19:45:38,830 INFO : valid_misclass            0.22618\n2020-02-08 19:45:38,831 INFO : runtime                   151.66413\n2020-02-08 19:45:38,831 INFO : \n2020-02-08 19:47:36,553 INFO : Time only for training updates: 117.72s\n2020-02-08 19:48:06,614 INFO : Epoch 6\n2020-02-08 19:48:06,615 INFO : train_loss                0.69807\n2020-02-08 19:48:06,615 INFO : valid_loss                0.69561\n2020-02-08 19:48:06,616 INFO : train_misclass            0.23969\n2020-02-08 19:48:06,616 INFO : valid_misclass            0.23014\n2020-02-08 19:48:06,617 INFO : runtime                   157.24705\n2020-02-08 19:48:06,618 INFO : \n2020-02-08 19:49:49,675 INFO : Time only for training updates: 103.06s\n2020-02-08 19:50:19,389 INFO : Epoch 7\n2020-02-08 19:50:19,389 INFO : train_loss                0.69927\n2020-02-08 19:50:19,390 INFO : valid_loss                0.69771\n2020-02-08 19:50:19,390 INFO : train_misclass            0.24497\n2020-02-08 19:50:19,391 INFO : valid_misclass            0.23589\n2020-02-08 19:50:19,392 INFO : runtime                   133.12104\n2020-02-08 19:50:19,393 INFO : \n2020-02-08 19:52:12,570 INFO : Time only for training updates: 113.18s\n2020-02-08 19:52:39,181 INFO : Epoch 8\n2020-02-08 19:52:39,182 INFO : train_loss                0.70288\n2020-02-08 19:52:39,182 INFO : valid_loss                0.69990\n2020-02-08 19:52:39,183 INFO : train_misclass            0.24129\n2020-02-08 19:52:39,183 INFO : valid_misclass            0.23348\n2020-02-08 19:52:39,184 INFO : runtime                   142.89534\n2020-02-08 19:52:39,184 INFO : \n2020-02-08 19:54:14,916 INFO : Time only for training updates: 95.73s\n2020-02-08 19:54:41,525 INFO : Epoch 9\n2020-02-08 19:54:41,526 INFO : train_loss                0.69927\n2020-02-08 19:54:41,527 INFO : valid_loss                0.69708\n2020-02-08 19:54:41,527 INFO : train_misclass            0.23933\n2020-02-08 19:54:41,528 INFO : valid_misclass            0.23263\n2020-02-08 19:54:41,528 INFO : runtime                   122.34690\n2020-02-08 19:54:41,528 INFO : \n2020-02-08 19:56:18,966 INFO : Time only for training updates: 97.44s\n2020-02-08 19:56:44,877 INFO : Epoch 10\n2020-02-08 19:56:44,878 INFO : train_loss                0.70157\n2020-02-08 19:56:44,878 INFO : valid_loss                0.69866\n2020-02-08 19:56:44,879 INFO : train_misclass            0.23833\n2020-02-08 19:56:44,879 INFO : valid_misclass            0.23045\n2020-02-08 19:56:44,879 INFO : runtime                   124.04932\n2020-02-08 19:56:44,880 INFO : \n"
    },
    {
     "data": {
      "text/plain": "<braindecode.experiments.experiment.Experiment at 0x7f7199eb2810>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, scheduler='cosine'\n",
    "         ,validation_data=(x_test, y_test)\n",
    "         ,input_time_length = 450) # supercropsize for cropped training\n",
    "# Rk : here, 1 timestep = 1 / 250 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started loading file data/x_test.h5\nFinished loading the file.\n"
    }
   ],
   "source": [
    "x_challenge = data.load_x('data/x_test.h5')\n",
    "x_challenge = data.flatten_x(x_challenge).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the predictions of all the indepedent trials to return one classification for each subject\n",
    "def average_predictions(predictions, nb_trials = 40):\n",
    "    # number of samples\n",
    "    n = int(len(predictions) / nb_trials)\n",
    "    avg_preds = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        sample_preds = predictions[i*nb_trials:(i+1)*nb_trials]\n",
    "        avg_preds[i] = int(np.mean(sample_preds) > 0.5)\n",
    "    return avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_challenge = model.predict_classes(x_challenge)\n",
    "y_challenge2 = average_predictions(y_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_csv(y, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        writer.writerow(['id', 'label'])\n",
    "        for i in range(len(y)):\n",
    "            writer.writerow([str(i), str(int(y[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(y_challenge2, 'data/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vizualise the neural network (recepive field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}