{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondab01880b39f9c4020a8d680b488ee4bca",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "import core.data as data\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load nn model from braindecode\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from braindecode.models.deep4 import Deep4Net\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "import core.data as data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started loading file data/x_train.h5\nFinished loading the file.\nStarted loading file data/y_train.csv\nFinished loading the file.\n"
    }
   ],
   "source": [
    "# load data \n",
    "x_loaded, y_loaded = data.load_x('data/x_train.h5'), data.load_y('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "shape :  (24974, 7, 500) (12866, 7, 500) (24974,) (12866,)\nweights : [0.64203815 2.2600905 ]\n"
    }
   ],
   "source": [
    "# convert y to categorical with np.eye(d)[y_loaded]\n",
    "# and flatten the 40 independent samples\n",
    "x, y = data.flatten_x(x_loaded), data.flatten_y(y_loaded, repeat=40)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.66)\n",
    "x_train, x_test = x_train.squeeze(), x_test.squeeze()\n",
    "\n",
    "# Only one value : 0 or 1  \n",
    "y_train, y_test = np.argmax(y_train, axis=1), np.argmax(y_test, axis=1)\n",
    "\n",
    "# get class weights\n",
    "weights = data.class_weights(y_train)\n",
    "\n",
    "print('shape : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print('weights :', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = x_train.shape[1]\n",
    "input_time_length=x_train.shape[2]\n",
    "final_conv_length='auto'\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = Deep4Net(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=input_time_length,\n",
    "                        final_conv_length=final_conv_length)\n",
    "\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "criterion = lambda prediction, targets : F.nll_loss(prediction, targets, weight=torch.from_numpy(weights).float())\n",
    "model.compile(loss=criterion, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-03-01 23:22:02,478 INFO : Run until first stop...\n2020-03-01 23:22:46,042 INFO : Epoch 0\n2020-03-01 23:22:46,046 INFO : train_loss                20.10962\n2020-03-01 23:22:46,046 INFO : valid_loss                20.36946\n2020-03-01 23:22:46,049 INFO : train_misclass            0.25006\n2020-03-01 23:22:46,050 INFO : valid_misclass            0.24584\n2020-03-01 23:22:46,051 INFO : runtime                   0.00000\n2020-03-01 23:22:46,052 INFO : \n2020-03-01 23:24:39,128 INFO : Time only for training updates: 113.07s\n2020-03-01 23:25:09,666 INFO : Epoch 1\n2020-03-01 23:25:09,667 INFO : train_loss                0.71224\n2020-03-01 23:25:09,668 INFO : valid_loss                0.71162\n2020-03-01 23:25:09,668 INFO : train_misclass            0.22924\n2020-03-01 23:25:09,669 INFO : valid_misclass            0.22960\n2020-03-01 23:25:09,671 INFO : runtime                   156.63774\n2020-03-01 23:25:09,672 INFO : \n2020-03-01 23:27:01,367 INFO : Time only for training updates: 111.70s\n2020-03-01 23:27:37,200 INFO : Epoch 2\n2020-03-01 23:27:37,201 INFO : train_loss                0.69747\n2020-03-01 23:27:37,201 INFO : valid_loss                0.69788\n2020-03-01 23:27:37,202 INFO : train_misclass            0.23677\n2020-03-01 23:27:37,202 INFO : valid_misclass            0.23760\n2020-03-01 23:27:37,203 INFO : runtime                   142.23951\n2020-03-01 23:27:37,203 INFO : \n2020-03-01 23:29:50,178 INFO : Time only for training updates: 132.97s\n2020-03-01 23:30:34,587 INFO : Epoch 3\n2020-03-01 23:30:34,588 INFO : train_loss                0.69735\n2020-03-01 23:30:34,588 INFO : valid_loss                0.69794\n2020-03-01 23:30:34,589 INFO : train_misclass            0.23384\n2020-03-01 23:30:34,589 INFO : valid_misclass            0.23550\n2020-03-01 23:30:34,590 INFO : runtime                   168.81101\n2020-03-01 23:30:34,591 INFO : \n2020-03-01 23:32:53,114 INFO : Time only for training updates: 138.52s\n2020-03-01 23:33:40,805 INFO : Epoch 4\n2020-03-01 23:33:40,806 INFO : train_loss                0.69847\n2020-03-01 23:33:40,807 INFO : valid_loss                0.69978\n2020-03-01 23:33:40,815 INFO : train_misclass            0.24029\n2020-03-01 23:33:40,815 INFO : valid_misclass            0.23924\n2020-03-01 23:33:40,816 INFO : runtime                   182.93573\n2020-03-01 23:33:40,816 INFO : \n2020-03-01 23:35:41,905 INFO : Time only for training updates: 121.09s\n2020-03-01 23:36:17,971 INFO : Epoch 5\n2020-03-01 23:36:17,972 INFO : train_loss                0.70264\n2020-03-01 23:36:17,972 INFO : valid_loss                0.70406\n2020-03-01 23:36:17,973 INFO : train_misclass            0.23701\n2020-03-01 23:36:17,973 INFO : valid_misclass            0.23955\n2020-03-01 23:36:17,975 INFO : runtime                   168.79264\n2020-03-01 23:36:17,978 INFO : \n2020-03-01 23:38:14,776 INFO : Time only for training updates: 116.80s\n2020-03-01 23:38:59,116 INFO : Epoch 6\n2020-03-01 23:38:59,117 INFO : train_loss                0.70789\n2020-03-01 23:38:59,118 INFO : valid_loss                0.70638\n2020-03-01 23:38:59,118 INFO : train_misclass            0.24057\n2020-03-01 23:38:59,119 INFO : valid_misclass            0.24118\n2020-03-01 23:38:59,119 INFO : runtime                   152.86988\n2020-03-01 23:38:59,120 INFO : \n2020-03-01 23:41:26,317 INFO : Time only for training updates: 147.20s\n2020-03-01 23:42:22,107 INFO : Epoch 7\n2020-03-01 23:42:22,108 INFO : train_loss                0.70804\n2020-03-01 23:42:22,109 INFO : valid_loss                0.70770\n2020-03-01 23:42:22,109 INFO : train_misclass            0.23472\n2020-03-01 23:42:22,110 INFO : valid_misclass            0.23558\n2020-03-01 23:42:22,110 INFO : runtime                   191.54013\n2020-03-01 23:42:22,111 INFO : \n2020-03-01 23:44:26,641 INFO : Time only for training updates: 124.53s\n2020-03-01 23:45:08,925 INFO : Epoch 8\n2020-03-01 23:45:08,926 INFO : train_loss                0.70005\n2020-03-01 23:45:08,926 INFO : valid_loss                0.69984\n2020-03-01 23:45:08,927 INFO : train_misclass            0.23404\n2020-03-01 23:45:08,927 INFO : valid_misclass            0.23395\n2020-03-01 23:45:08,928 INFO : runtime                   180.32442\n2020-03-01 23:45:08,928 INFO : \n2020-03-01 23:47:13,388 INFO : Time only for training updates: 124.46s\n2020-03-01 23:47:48,795 INFO : Epoch 9\n2020-03-01 23:47:48,796 INFO : train_loss                0.70064\n2020-03-01 23:47:48,797 INFO : valid_loss                0.70050\n2020-03-01 23:47:48,797 INFO : train_misclass            0.23136\n2020-03-01 23:47:48,798 INFO : valid_misclass            0.23193\n2020-03-01 23:47:48,798 INFO : runtime                   166.74739\n2020-03-01 23:47:48,799 INFO : \n2020-03-01 23:49:50,738 INFO : Time only for training updates: 121.94s\n2020-03-01 23:50:36,939 INFO : Epoch 10\n2020-03-01 23:50:36,940 INFO : train_loss                0.70040\n2020-03-01 23:50:36,941 INFO : valid_loss                0.70045\n2020-03-01 23:50:36,941 INFO : train_misclass            0.23280\n2020-03-01 23:50:36,942 INFO : valid_misclass            0.23442\n2020-03-01 23:50:36,942 INFO : runtime                   157.34982\n2020-03-01 23:50:36,942 INFO : \n"
    },
    {
     "data": {
      "text/plain": "<braindecode.experiments.experiment.Experiment at 0x7f493d196d10>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64, scheduler='cosine'\n",
    "         ,validation_data=(x_test, y_test)\n",
    "         ,input_time_length = 450) # supercropsize for cropped training\n",
    "# Rk : here, 1 timestep = 1 / 250 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started loading file data/x_test.h5\nFinished loading the file.\n"
    }
   ],
   "source": [
    "x_challenge = data.load_x('data/x_test.h5')\n",
    "x_challenge = data.flatten_x(x_challenge).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the predictions of all the indepedent trials to return one classification for each subject\n",
    "def average_predictions(predictions, nb_trials = 40):\n",
    "    # number of samples\n",
    "    n = int(len(predictions) / nb_trials)\n",
    "    avg_preds = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        sample_preds = predictions[i*nb_trials:(i+1)*nb_trials]\n",
    "        avg_preds[i] = int(np.mean(sample_preds) > 0.5)\n",
    "    return avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_challenge = model.predict_classes(x_challenge)\n",
    "y_challenge2 = data.average_predictions(y_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(y_challenge2, 'data/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vizualise the neural network (recepive field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}