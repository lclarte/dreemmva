{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondab01880b39f9c4020a8d680b488ee4bca",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braindecode\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load nn model from braindecode\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "import core.data as data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Started loading file data/x_train.h5\nFinished loading the file.\nStarted loading file data/y_train.csv\nFinished loading the file.\n"
    }
   ],
   "source": [
    "# load data \n",
    "x_loaded, y_loaded = data.load_x('data/x_train.h5'), data.load_y('data/y_train.csv')[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "shape :  (24974, 7, 500) (12866, 7, 500) (24974,) (12866,)\n"
    }
   ],
   "source": [
    "# convert y to categorical with np.eye(d)[y_loaded]\n",
    "# and flatten the 40 independent samples\n",
    "x, y = data.flatten_x(x_loaded), data.flatten_y(np.eye(2)[y_loaded], repeat=40)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.66)\n",
    "x_train, x_test = x_train.squeeze(), x_test.squeeze() \n",
    "\n",
    "# Only one value : 0 or 1  \n",
    "y_train, y_test = np.argmax(y_train, axis=1), np.argmax(y_test, axis=1)\n",
    "print('shape : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = x_train.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=x_train.shape[2],\n",
    "                        final_conv_length='auto')\n",
    "\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-07 20:04:19,289 INFO : Run until first stop...\n2020-02-07 20:04:47,298 INFO : Epoch 0\n2020-02-07 20:04:47,299 INFO : train_loss                2.64547\n2020-02-07 20:04:47,301 INFO : valid_loss                2.65069\n2020-02-07 20:04:47,302 INFO : train_misclass            0.73452\n2020-02-07 20:04:47,304 INFO : valid_misclass            0.73993\n2020-02-07 20:04:47,305 INFO : runtime                   0.00000\n2020-02-07 20:04:47,307 INFO : \n2020-02-07 20:06:23,473 INFO : Time only for training updates: 96.16s\n2020-02-07 20:06:56,814 INFO : Epoch 1\n2020-02-07 20:06:56,815 INFO : train_loss                1.23345\n2020-02-07 20:06:56,818 INFO : valid_loss                1.21751\n2020-02-07 20:06:56,819 INFO : train_misclass            0.23356\n2020-02-07 20:06:56,821 INFO : valid_misclass            0.22929\n2020-02-07 20:06:56,824 INFO : runtime                   124.18296\n2020-02-07 20:06:56,828 INFO : \n2020-02-07 20:08:44,797 INFO : Time only for training updates: 107.96s\n2020-02-07 20:09:15,666 INFO : Epoch 2\n2020-02-07 20:09:15,669 INFO : train_loss                0.60720\n2020-02-07 20:09:15,669 INFO : valid_loss                0.60015\n2020-02-07 20:09:15,670 INFO : train_misclass            0.22776\n2020-02-07 20:09:15,670 INFO : valid_misclass            0.22431\n2020-02-07 20:09:15,671 INFO : runtime                   141.32976\n2020-02-07 20:09:15,671 INFO : \n2020-02-07 20:11:22,802 INFO : Time only for training updates: 127.13s\n2020-02-07 20:12:00,379 INFO : Epoch 3\n2020-02-07 20:12:00,380 INFO : train_loss                0.51760\n2020-02-07 20:12:00,381 INFO : valid_loss                0.51507\n2020-02-07 20:12:00,381 INFO : train_misclass            0.22203\n2020-02-07 20:12:00,381 INFO : valid_misclass            0.21903\n2020-02-07 20:12:00,382 INFO : runtime                   158.00233\n2020-02-07 20:12:00,382 INFO : \n"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(x_test, y_test),)"
   ]
  }
 ]
}